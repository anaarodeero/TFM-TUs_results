common:

  output_directory: OpusFilter-output

steps:
#1
  - type: opus_read
    parameters:
      corpus_name: News-Commentary
      source_language: en
      target_language: es
      release: v16
      preprocessing: raw
      src_output: NewsCommentary.en.gz
      tgt_output: NewsCommentary.es.gz
#2   
  - type: subset
    parameters:
      inputs: [NewsCommentary.en.gz, NewsCommentary.es.gz]
      outputs: [subset_100k.en.gz, subset_100k.es.gz]
      seed: 123
      size: 100000
#3     
  - type: filter
    parameters:
      inputs: [NewsCommentary.en.gz, NewsCommentary.es.gz]
      outputs: [filtered.en.gz, filtered.es.gz]
      filters:
        - LengthFilter:
            unit: word
            min_length: 1
            max_length: 100

        - LengthRatioFilter:
            unit: word
            threshold: 3

        - LongWordFilter:
            threshold: 40

        - HtmlTagFilter: {}

        - CharacterScoreFilter:
            scripts: [Latin, Latin]
            thresholds: [1, 1]
#4            
  - type: concatenate
    parameters:
      inputs:
      - NewsCommentary.en.gz
      - NewsCommentary.es.gz
      output: concatenated.gz
#5
  - type: train_ngram
    parameters:
      data: concatenated.gz
      parameters:
        norder: 5
        dscale: 1
      model: bg.arpa.gz
#6            
  - type: train_ngram
    parameters:
      data: filtered.en.gz
      parameters:
        norder: 15
        dscale: 0.1
      model: en.arpa.gz
#7
  - type: train_ngram
    parameters:
      data: filtered.es.gz
      parameters:
        norder: 15
        dscale: 0.1
      model: es.arpa.gz
#8      
  - type: train_alignment
    parameters:
      src_data: filtered.en.gz
      tgt_data: filtered.es.gz
      parameters:
        src_tokenizer: [moses, en]
        tgt_tokenizer: [moses, es]
        model: 3
      output: align.priors

#9
  - type: score
    parameters:
      inputs: [subset_100k.en.gz, subset_100k.es.gz]
      output: NewsCommentary-scores.es-en.jsonl.gz
      filters: &scorefilt

        - LengthRatioFilter:
            name: char
            unit: char

        - LengthRatioFilter:
            name: word
            unit: word
            
        - LanguageIDFilter:
            name: langid
            id_method: langid
            languages: [en, es]

        - LanguageIDFilter:
            name: cld2
            id_method: cld2
            languages: [en, es]
            
        - TerminalPunctuationFilter: {}

        - NonZeroNumeralsFilter: {}
        
        - CrossEntropyFilter:
            lm_params:
              - filename: en.arpa.gz
                interpolate:
                - [bg.arpa.gz, 0.01]
              - filename: es.arpa.gz
                interpolate:
                - [bg.arpa.gz, 0.01]
        
        - WordAlignFilter:
            src_tokenizer: [moses, en]
            tgt_tokenizer: [moses, es]
            model: 3
            priors: align.priors

#10     
  - type: train_classifier
    parameters:
        training_scores: NewsCommentary-scores.es-en.jsonl.gz
        criterion: CE
        model_type: LogisticRegression
        model_parameters:
            solver: liblinear
        model: ce_model
        features:
            LengthRatioFilter:
                clean-direction: high
                quantiles: &def_quant
                    min: 0
                    max: 0.2
                    initial: 0.01
            LanguageIDFilter:
                clean-direction: high
                quantiles: *def_quant
            CrossEntropyFilter:
                clean-direction: low
                quantiles: *def_quant
            NonZeroNumeralsFilter:
                clean-direction: high
                quantiles: *def_quant
            TerminalPunctuationFilter:
                clean-direction: high
                quantiles: *def_quant
            WordAlignFilter:
                clean-direction: low
                quantiles: *def_quant
      
      
